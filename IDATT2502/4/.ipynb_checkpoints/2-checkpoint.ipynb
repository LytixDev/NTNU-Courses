{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daf4e699-da63-4a8e-8b08-e90c12427596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a4fa36f-aa96-4290-909b-c3f7119d0240",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LongShortTermMemoryModel(nn.Module):\n",
    "\n",
    "    def __init__(self, encoding_size, emoji_size):\n",
    "        super(LongShortTermMemoryModel, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(encoding_size, 128)  # 128 is the state size\n",
    "        self.dense = nn.Linear(128, emoji_size)  # 128 is the state size\n",
    "\n",
    "    def reset(self):  # Reset states prior to new input sequence\n",
    "        zero_state = torch.zeros(1, 1, 128)  # Shape: (number of layers, batch size, state size)\n",
    "        self.hidden_state = zero_state\n",
    "        self.cell_state = zero_state\n",
    "\n",
    "    def logits(self, x):  # x shape: (sequence length, batch size, encoding size)\n",
    "        out, (self.hidden_state, self.cell_state) = self.lstm(x, (self.hidden_state, self.cell_state))\n",
    "        return self.dense(out.reshape(-1, 128))\n",
    "\n",
    "    def f(self, x):  # x shape: (sequence length, batch size, encoding size)\n",
    "        return torch.softmax(self.logits(x), dim=1)\n",
    "\n",
    "    def loss(self, x, y):  # x shape: (sequence length, batch size, encoding size), y shape: (sequence length, encoding size)\n",
    "        return nn.functional.cross_entropy(self.logits(x), y.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f1c3b484-e83e-45b5-a2e2-03d27cee2c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = [\" \", \"h\", \"a\", \"t\", \"r\", \"c\", \"f\", \"l\"]\n",
    "char_encodings = []\n",
    "for i, _ in enumerate(chars):\n",
    "    encoding = [0.0 for _ in range(i)]\n",
    "    encoding.append(1.0)\n",
    "    for _ in range(len(chars) - i - 1):\n",
    "        encoding.append(0.0)\n",
    "    char_encodings.append(encoding)\n",
    "\n",
    "char_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b68a6a2-c7f9-42c3-8db5-45c2828be34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hat -> üé©\n",
      "rat -> üêÄ\n",
      "cat -> üêà\n",
      "flat -> üè¢\n"
     ]
    }
   ],
   "source": [
    "emojis = {\n",
    "    \"hat\": \"üé©\",\n",
    "    \"rat\": \"üêÄ\",\n",
    "    \"cat\": \"üêà\",\n",
    "    \"flat\": \"üè¢\",   \n",
    "}\n",
    "for k, v in emojis.items():\n",
    "    print(k, \"->\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb21c292-d706-4420-8860-daaf8ada73bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = emojis.values()\n",
    "encodings = []\n",
    "for i, _ in enumerate(values):\n",
    "    encoding = [0.0 for _ in range(i)]\n",
    "    encoding.append(1.0)\n",
    "    for _ in range(len(values) - i - 1):\n",
    "        encoding.append(0.0)\n",
    "    encodings.append(encoding)\n",
    "encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f113f7f2-ef3f-4e27-b4f8-bbcc013bba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor([[[char_encodings[1]], [char_encodings[2]], [char_encodings[3]], [char_encodings[0]]],\n",
    "                        [[char_encodings[4]], [char_encodings[2]], [char_encodings[3]], [char_encodings[0]]], \n",
    "                        [[char_encodings[5]], [char_encodings[2]], [char_encodings[3]], [char_encodings[0]]],\n",
    "                        [[char_encodings[6]], [char_encodings[7]], [char_encodings[2]], [char_encodings[3]]]], dtype=torch.float)\n",
    "\n",
    "\n",
    "y_train = torch.tensor([[encodings[0] for _ in range(4)],\n",
    "                        [encodings[1] for _ in range(4)],\n",
    "                        [encodings[2] for _ in range(4)],\n",
    "                        [encodings[3] for _ in range(4)]], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "31ac66fd-be06-4e49-9833-1f296bd8426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LongShortTermMemoryModel(len(char_encodings), len(encodings))\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), 0.001)  # 0.001\n",
    "for epoch in range(500):\n",
    "    for i in range(4):\n",
    "        model.reset()\n",
    "        model.loss(x_train[i], y_train[i]).backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d72bad00-130b-40c1-837a-328c8f469c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_values = list(emojis.items())\n",
    "def predict(x: str):\n",
    "    y = -1\n",
    "    model.reset()\n",
    "    for i in range(len(x)):\n",
    "        y = model.f(torch.tensor([[char_encodings[chars.index(x[i])]]], dtype=torch.float))\n",
    "    print(emoji_values[y.argmax(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f7164be-4ecc-4404-b667-f3fee23f4f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('hat', 'üé©')\n",
      "('hat', 'üé©')\n",
      "('cat', 'üêà')\n",
      "('cat', 'üêà')\n",
      "('cat', 'üêà')\n"
     ]
    }
   ],
   "source": [
    "predict(\"hat\")\n",
    "predict(\"ha\")\n",
    "predict(\"cat\")\n",
    "predict(\"catt\")\n",
    "predict(\"ca\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
